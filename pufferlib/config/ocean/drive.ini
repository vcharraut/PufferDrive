[base]
package = ocean
env_name = puffer_drive
policy_name = Drive
rnn_name = Recurrent

[vec]
num_workers = 8
num_envs = 8
batch_size = 2
#backend = Serial

[policy]
input_size = 64
hidden_size = 256

[rnn]
input_size = 256
hidden_size = 256

[env]
num_agents = 1024
reward_vehicle_collision = -0.5
reward_offroad_collision = -0.2
spawn_immunity_timer = 50   
reward_goal_post_respawn = 0.25
reward_vehicle_collision_post_respawn = -0.5
resample_frequency = 910
num_maps = 80000

[train]
total_timesteps = 2_000_000_000
#learning_rate = 0.02
#gamma = 0.985
anneal_lr = True
batch_size = 745472
minibatch_size = 11648
max_minibatch_size = 11648
bptt_horizon = 91
adam_beta1 = 0.9
adam_beta2 = 0.999
adam_eps = 1e-8
clip_coef = 0.2
ent_coef = 0.001
gae_lambda = 0.95
gamma = 0.98
learning_rate = 0.001
max_grad_norm = 1
prio_alpha = 0.8499999999999999
prio_beta0 = 0.8499999999999999
update_epochs = 1
vf_clip_coef = 0.1999999999999999
vf_coef = 2
vtrace_c_clip = 1
vtrace_rho_clip = 1
checkpoint_interval = 1000



[sweep.train.total_timesteps]
distribution = log_normal
min = 1e8
max = 4e8
mean = 2e8
scale = time
 
[sweep.env.reward_vehicle_collision]
distribution = uniform
min = -1.0
max = 0.0
mean = -0.2
scale = auto 
 
[sweep.env.reward_offroad_collision]
distribution = uniform
min = -1.0
max = 0.0
mean = -0.2
scale = auto

[sweep.env.spawn_immunity_timer]
distribution = uniform
min = 1
max = 91
mean = 30
scale = auto

[sweep.env.reward_goal_post_respawn]
distribution = uniform
min = 0.0
max = 1.0
mean = 0.5
scale = auto

[sweep.env.reward_vehicle_collision_post_respawn]
distribution = uniform
min = -1.0
max = 0.0
mean = -0.2
scale = auto
